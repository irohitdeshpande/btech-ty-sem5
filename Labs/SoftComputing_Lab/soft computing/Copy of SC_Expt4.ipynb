{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1OKoJxOLEpb5o2HzdGoacoNmxOWgEQxU-","timestamp":1723015860370}],"authorship_tag":"ABX9TyMI1GADjymbCx7AcwLCDbQA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Implement Perceptron learning network for AND function using bipolar input and target"],"metadata":{"id":"tENJ9RTKuobx"}},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BdPLtjdDfvzY","executionInfo":{"status":"ok","timestamp":1723012634950,"user_tz":-330,"elapsed":565,"user":{"displayName":"Rohit Deshpande","userId":"11530750372540555607"}},"outputId":"e67453b3-21ad-42a5-88be-b6ba2e3eb965"},"outputs":[{"output_type":"stream","name":"stdout","text":["Weights after training: [-0.07272805  0.75271148  0.78394987]\n","For input [-1 -1], prediction: 0\n","For input [-1  1], prediction: 0\n","For input [ 1 -1], prediction: 0\n","For input [1 1], prediction: 1\n"]}],"source":["import numpy as np\n","\n","class Perceptron:\n","    def __init__(self, input_size, learning_rate=0.1, epochs=100):\n","        self.weights = np.random.rand(input_size + 1)  # +1 for the bias weight\n","        self.learning_rate = learning_rate\n","        self.epochs = epochs\n","\n","    def activate(self, x):\n","        # Activation function (step function)\n","        return 1 if x >= 0 else 0\n","\n","    def train(self, X, y):\n","        X = np.insert(X, 0, 1, axis=1)  # Adding bias input (always 1)\n","\n","        for _ in range(self.epochs):\n","            total_error = 0\n","            for i in range(X.shape[0]):\n","                prediction = self.activate(np.dot(self.weights, X[i]))\n","                error = y[i] - prediction\n","                total_error += abs(error)\n","                self.weights += self.learning_rate * error * X[i]\n","            if total_error == 0:\n","                break\n","\n","    def predict(self, X):\n","        X = np.insert(X, 0, 1)  # Adding bias input (always 1)\n","        return self.activate(np.dot(self.weights, X))\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n","    y = np.array([0, 0, 0, 1])  # Adjusted labels to 0 and 1\n","\n","    perceptron = Perceptron(input_size=2)\n","    perceptron.train(X, y)\n","\n","    print(\"Weights after training:\", perceptron.weights)\n","\n","    test_data = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n","    for data in test_data:\n","        prediction = perceptron.predict(data)\n","        print(f\"For input {data}, prediction: {prediction}\")\n"]},{"cell_type":"code","source":["import numpy as np\n","\n","X = np.array([\n","    [-1, -1],\n","    [-1,  1],\n","    [ 1, -1],\n","    [ 1,  1]\n","])\n","\n","y = np.array([-1, -1, -1, 1])\n","\n","# Initialize weights and bias\n","weights = np.zeros(X.shape[1])\n","bias = 0\n","learning_rate = 1\n","\n","# Sign activation function\n","def activation_function(x):\n","    return 1 if x >= 0 else -1\n","\n","# Perceptron learning algorithm\n","def train_perceptron(X, y, weights, bias, learning_rate, epochs):\n","    for epoch in range(epochs):\n","        print(f'Epoch {epoch+1}')\n","        for inputs, target in zip(X, y):\n","            # net input\n","            net_input = np.dot(inputs, weights) + bias\n","            # output\n","            output = activation_function(net_input)\n","            # error\n","            error = target - output\n","            # Update\n","            weights += learning_rate * error * inputs\n","            bias += learning_rate * error\n","            print(f'Inputs: {inputs}, Target: {target}, Output: {output}, Error: {error}, Weights: {weights}, Bias: {bias}')\n","        print('')\n","\n","# Training\n","epochs = 10\n","train_perceptron(X, y, weights, bias, learning_rate, epochs)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kggcAIo4tgCj","executionInfo":{"status":"ok","timestamp":1723015243676,"user_tz":-330,"elapsed":1735,"user":{"displayName":"Rohit Deshpande","userId":"11530750372540555607"}},"outputId":"bf20b170-ffe0-4139-a2ea-ded7e7593971"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","Inputs: [-1 -1], Target: -1, Output: 1, Error: -2, Weights: [2. 2.], Bias: -2\n","Inputs: [-1  1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [ 1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [1 1], Target: 1, Output: 1, Error: 0, Weights: [2. 2.], Bias: -2\n","\n","Epoch 2\n","Inputs: [-1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [-1  1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [ 1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [1 1], Target: 1, Output: 1, Error: 0, Weights: [2. 2.], Bias: -2\n","\n","Epoch 3\n","Inputs: [-1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [-1  1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [ 1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [1 1], Target: 1, Output: 1, Error: 0, Weights: [2. 2.], Bias: -2\n","\n","Epoch 4\n","Inputs: [-1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [-1  1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [ 1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [1 1], Target: 1, Output: 1, Error: 0, Weights: [2. 2.], Bias: -2\n","\n","Epoch 5\n","Inputs: [-1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [-1  1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [ 1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [1 1], Target: 1, Output: 1, Error: 0, Weights: [2. 2.], Bias: -2\n","\n","Epoch 6\n","Inputs: [-1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [-1  1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [ 1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [1 1], Target: 1, Output: 1, Error: 0, Weights: [2. 2.], Bias: -2\n","\n","Epoch 7\n","Inputs: [-1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [-1  1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [ 1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [1 1], Target: 1, Output: 1, Error: 0, Weights: [2. 2.], Bias: -2\n","\n","Epoch 8\n","Inputs: [-1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [-1  1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [ 1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [1 1], Target: 1, Output: 1, Error: 0, Weights: [2. 2.], Bias: -2\n","\n","Epoch 9\n","Inputs: [-1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [-1  1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [ 1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [1 1], Target: 1, Output: 1, Error: 0, Weights: [2. 2.], Bias: -2\n","\n","Epoch 10\n","Inputs: [-1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [-1  1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [ 1 -1], Target: -1, Output: -1, Error: 0, Weights: [2. 2.], Bias: -2\n","Inputs: [1 1], Target: 1, Output: 1, Error: 0, Weights: [2. 2.], Bias: -2\n","\n"]}]}]}